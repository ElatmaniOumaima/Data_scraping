{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85fa15a9-4fb6-4b03-88fc-3279e9e40472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import webdriver_manager\n",
    "import time\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "902c6765-fd2f-43f6-91da-c7a2f026a025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emploi | Indeed\n",
      "62\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "NA\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "NA\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "18\n",
      "NA\n",
      "NA\n",
      "      nom_entreprise                            ville   royaume1  \\\n",
      "0           Deloitte                  Sydney NSW 2000  Australie   \n",
      "1               Bupa       Hybrid remote in Australia  Australie   \n",
      "2           Black.ai                        Australia  Australie   \n",
      "3             Foxtel  Hybrid remote in North Ryde NSW  Australie   \n",
      "4          Sportsbet                    Melbourne VIC  Australie   \n",
      "...              ...                              ...        ...   \n",
      "1777  Manning Global                           Oeiras   Portugal   \n",
      "1778          Maersk                            Porto   Portugal   \n",
      "1779           Amgen                           Lisboa   Portugal   \n",
      "1780     BNP Paribas         Remoto híbrido in Lisboa   Portugal   \n",
      "1781          Noesis                           Lisboa   Portugal   \n",
      "\n",
      "                                   travail_description type_travail  \\\n",
      "0                       Data Scientist | Generative AI                \n",
      "1                 Learning Systems and Data Specialist                \n",
      "2                            Machine Learning Engineer                \n",
      "3                          Data & Analytics Specialist                \n",
      "4                                       Data Scientist                \n",
      "...                                                ...          ...   \n",
      "1777                              Safety Content Rater                \n",
      "1778                                     Data Engineer                \n",
      "1779  Spanish Speaking Document Controller Coordinator                \n",
      "1780                 FRESH EMEA - IT Job Opportunities                \n",
      "1781                                      Data Analyst                \n",
      "\n",
      "                          publication_date  \\\n",
      "0                Posted\\nPosted 3 days ago   \n",
      "1                Posted\\nPosted 3 days ago   \n",
      "2              Posted\\nPosted 30+ days ago   \n",
      "3                Posted\\nPosted 3 days ago   \n",
      "4                Posted\\nPosted 7 days ago   \n",
      "...                                    ...   \n",
      "1777  Posted\\nAnunciada há mais de 30 dias   \n",
      "1778          Posted\\nAnunciada há 13 dias   \n",
      "1779                   Posted\\nAgora mesmo   \n",
      "1780  Posted\\nAnunciada há mais de 30 dias   \n",
      "1781  Posted\\nAnunciada há mais de 30 dias   \n",
      "\n",
      "                                       job_requirement1 scraping_date  \n",
      "0     A minimum 5 years’ relevant work experience wi...    18-01-2024  \n",
      "1     Tertiary qualifications in Technology or simil...    18-01-2024  \n",
      "2     Masters or PhD in fields related to computer s...    18-01-2024  \n",
      "3     You’re skilled in data science, maths and stat...    18-01-2024  \n",
      "4     From sports modelling to product personalisati...    18-01-2024  \n",
      "...                                                 ...           ...  \n",
      "1777  Experience/ or being comfortable working on se...    18-01-2024  \n",
      "1778  Hands on experience in Azure, preferably data ...    18-01-2024  \n",
      "1779  University Degree, preferably in business or a...    18-01-2024  \n",
      "1780  Education Level: Bachelor Degree or equivalent...    18-01-2024  \n",
      "1781  Degree in Computer Science or similar;\\nKnowle...    18-01-2024  \n",
      "\n",
      "[1782 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "##initialize the list of intrested countries\n",
    "\n",
    "os.environ[\"PATH\"]+=r\"C:/chromedriver-win64\"\n",
    "url=\"https://ma.indeed.com/\"\n",
    "#instancier le webdriver \n",
    "driver=webdriver.Chrome()\n",
    "\n",
    "page=driver.get(url)\n",
    "#get the title \n",
    "page_title=driver.title\n",
    "print(page_title)\n",
    "time.sleep(5)\n",
    "countries= driver.find_element(By.XPATH, '//*[@id=\"gnav-footer-container\"]/div/footer/div/ul[1]/li[3]/a')\n",
    "countries.click()\n",
    "\n",
    "international=driver.find_element(By.XPATH,'//*[@id=\"page\"]/div/div/ul')\n",
    "pays=international.find_elements(By.TAG_NAME,\"li\")\n",
    "r=len(pays)#the list lenght\n",
    "print(r)#le nombre des pays existant en indeed qu'on vas y extraire the job oppotunities\n",
    "\n",
    "L=[]# initialize the dataframe\n",
    "for i in range(r):\n",
    "      royaume=pays[i].text\n",
    "      intrested_countries=[\"Maroc\",\"France\",\"canada\",\"Australie\",\"chine\",\"Portugal\",\"italie\",\"Belgique\",\"Espagne\"]\n",
    "      if royaume in intrested_countries:\n",
    "          pays[i].find_element(By.TAG_NAME,\"a\").click()\n",
    "          post=driver.find_element(By.NAME,\"q\")\n",
    "          post.click()\n",
    "          time.sleep(4)\n",
    "          post.send_keys(\"Data science,Data analytics,AI,ML,machine learning,Data scrapingn,NLP\")\n",
    "          \n",
    "          search=driver.find_element(By.XPATH,'//*[@id=\"jobsearch\"]/div/div[2]/button')\n",
    "          search.send_keys(Keys.RETURN)\n",
    "          ##pagination for every country \n",
    "          nav =driver.find_element(By.XPATH,\"//*[@id='jobsearch-JapanPage']/div/div[5]/div[1]/nav\")\n",
    "          lis3=nav.find_element(By.TAG_NAME,\"ul\")\n",
    "          lies=lis3.find_elements(By.TAG_NAME,\"li\")\n",
    "          N=20 #the number of page that we want exract \n",
    "          while True:\n",
    "                lies[-1].find_element(By.TAG_NAME,\"a\").click()\n",
    "                 #when the page gonna be clicked , we exract all the links and clicked on them one by one , finaly exract the data \n",
    "                div_jobs_results=driver.find_element(By.ID,\"jobsearch-Main\")\n",
    "                job_job_list=div_jobs_results.find_element(By.XPATH,'//*[@id=\"jobsearch-JapanPage\"]/div/div[5]/div[1]')\n",
    "                data_list=job_job_list.find_element(By.XPATH,'//*[@id=\"mosaic-jobResults\"]')\n",
    "                ul=data_list.find_element(By.CSS_SELECTOR,\"#mosaic-provider-jobcards > ul\")\n",
    "                data_list2=ul.find_elements(By.CSS_SELECTOR,\"#mosaic-provider-jobcards > ul > li\")\n",
    "                #for j in range(len(data_list2)):\n",
    "                print(len(data_list2))\n",
    "                N1=0\n",
    "                while True:\n",
    "                      #get the table\n",
    "                      try:\n",
    "                            \n",
    "                            job_description=data_list2[N1].find_element(By.TAG_NAME,\"h2\").text\n",
    "                            company_name=data_list2[N1].find_element(By.CSS_SELECTOR,\"#mosaic-provider-jobcards > ul > li > div > div> div > div > div > table > tbody > tr > td > div > div > span\").text\n",
    "                            city=data_list2[N1].find_element(By.CSS_SELECTOR,\"#mosaic-provider-jobcards > ul > li > div > div > div > div > div > table> tbody > tr > td > div > div > div\").text\n",
    "                            job_type=data_list2[N1].find_elements(By.CSS_SELECTOR,\"#mosaic-provider-jobcards > ul > li > div > div > div > div> div > table> tbody > tr > td > div\")[2].text\n",
    "                            date_publication=data_list2[N1].find_element(By.CSS_SELECTOR,\"#mosaic-provider-jobcards > ul > li > div > div> div > div> div > table > tbody > tr > td > div > span.date\").text\n",
    "                            #scraping_date=\n",
    "                            job_requirement=data_list2[N1].find_element(By.CSS_SELECTOR,\"#mosaic-provider-jobcards > ul > li > div > div > div > div > div > table > tbody > tr > td > div.heading6.tapItem-gutter.result-footer > div\").text\n",
    "                            #link_for_applying=data_list2[N1].find_element(By.XPATH,\"//*[@id='applyButtonLinkContainer'']/div/div/button\")\n",
    "                            full_data=dict(nom_entreprise=company_name,ville=city,royaume1=royaume,travail_description=job_description,\n",
    "                                           type_travail=job_type,publication_date=date_publication,job_requirement1=job_requirement,scraping_date=datetime.now().strftime(\"%d-%m-%Y\"))\n",
    "                            L.append(full_data)      \n",
    "                      except:\n",
    "                            print(\"NA\")\n",
    "    \n",
    "                      \n",
    "                      N1+=1\n",
    "                      if N1==len(data_list2):\n",
    "                        break\n",
    "                      elif N1==5:\n",
    "                            N1+=1\n",
    "                #print(pd.DataFrame(L))     \n",
    "                      \n",
    "                #we must iterate over the list elements ,and each jobs li  \"mosaic-afterFifthJobResult\" \n",
    "                          \n",
    "                time.sleep(5)\n",
    "               \n",
    "                #i put N as number of pages cuz the while loop gonna run infinittly for that we have to set a break condition and precize how many pages we want \n",
    "                N-=1\n",
    "                if N==0:\n",
    "                      break \n",
    "                nav =driver.find_element(By.XPATH,\"//*[@id='jobsearch-JapanPage']/div/div[5]/div[1]/nav\")\n",
    "                lis3=nav.find_element(By.TAG_NAME,\"ul\")\n",
    "                lies=lis3.find_elements(By.TAG_NAME,\"li\")\n",
    "                time.sleep(5)\n",
    "          page1=driver.get(\"https://ma.indeed.com/worldwide\")\n",
    "          international=driver.find_element(By.XPATH,'//*[@id=\"page\"]/div/div/ul')\n",
    "          pays=international.find_elements(By.TAG_NAME,\"li\")\n",
    "      else:\n",
    "          continue\n",
    "\n",
    "Data_final_exracted=pd.DataFrame(L)  \n",
    "print(Data_final_exracted)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "684f7d1b-a297-41d0-b5c1-6ba1719159f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_final_exracted.to_csv(\"C:/Users/Oumaima/Desktop/S3/Data_scraping_course/Selenium/Indeed2.csv\")#export the actual data to workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eb76f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
